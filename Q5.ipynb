{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob, time\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the process took 2.46 s\n"
     ]
    }
   ],
   "source": [
    "def make_R(filename, col_user, col_item, col_rating, fraction = 0.8):\n",
    "    start_time = time.time()\n",
    "    '''create R matrix from a file that contains a table of user IDs, item IDs and ratings\n",
    "    parameters:\n",
    "        filename: str; the filename of the table\n",
    "        col_user: str; the column name of user IDs\n",
    "        col_item: str; the column name of item IDs\n",
    "        col_rating: str; the column name of the ratings\n",
    "        fraction: float; the fraction of data to be used for training\n",
    "    returns:\n",
    "        rTrain: 2D numpy array; training R matrix in with r_{i, j} is the rating that user i given to item j\n",
    "        rTest: 2D numpy array; testing R matrix in with r_{i, j} is the rating that user i given to item j'''\n",
    "    t = ascii.read(filename)\n",
    "    nData = np.size(t) # total number of data points(ratings)\n",
    "    nTrain = int(np.rint(fraction * nData)) # number of training data\n",
    "    nUser = np.max(t[col_user]) # total number of users\n",
    "    nitem = np.max(t[col_item]) # total number of items\n",
    "    \n",
    "    idxData = np.arange(nData) # an array of idx of data\n",
    "    np.random.shuffle(idxData) # randomize idx\n",
    "    idxTrain, idxTest = idxData[:nTrain], idxData[nTrain:]\n",
    "    \n",
    "    idxUser = t.index_column(col_user)\n",
    "    idxItem = t.index_column(col_item)\n",
    "    idxRating = t.index_column(col_rating)\n",
    "    \n",
    "    rTrain = np.zeros(shape = (nUser, nitem))\n",
    "    rTest = np.zeros(shape = (nUser, nitem))\n",
    "    for nrow in idxTrain:\n",
    "        i = t[nrow][idxUser] - 1 # the userId\n",
    "        j = t[nrow][idxItem] - 1 # the itemId\n",
    "        rTrain[i][j] = t[nrow][idxRating] # the rating\n",
    "    \n",
    "    for nrow in idxTest:\n",
    "        i = t[nrow][idxUser] - 1 # the userId\n",
    "        j = t[nrow][idxItem] - 1 # the itemId\n",
    "        rTest[i][j] = t[nrow][idxRating] # the rating\n",
    "    \n",
    "    print('the process took %.2f s' % (time.time() - start_time))\n",
    "    return rTrain, rTest\n",
    "\n",
    "R_train, R_test = make_R(filename = 'movie_ratings.csv', col_user = 'userId', col_item = 'movieId', col_rating = 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "class recommendation_system():\n",
    "\n",
    "    def __init__(self, R_train, R_test):\n",
    "        '''R_train: 2D numpy array; R matrix in with r_{i, j} is the rating that user i given to item j'''\n",
    "        self.R_train = R_train\n",
    "        self.R_test = R_test\n",
    "        self.nUser, self.nItem = R_train.shape\n",
    "        self.result = None\n",
    "\n",
    "    def matrix_factorization(self, k, alpha, _lambda, iterations):\n",
    "        '''perform matrix factorization to predict empty entries in a matrix.\n",
    "        parameters:\n",
    "            k: int; dimensions of u and v vector\n",
    "            alpha: float; learning rate\n",
    "            _lambda: float; regularization parameter'''\n",
    "        self.k = k\n",
    "        self.alpha = alpha\n",
    "        self.iterations = iterations\n",
    "        self._lambda = _lambda\n",
    "        \n",
    "        def sgd():\n",
    "            '''stochastic graident descent'''\n",
    "            for i, j, r in self.samples:\n",
    "                # Computer prediction and error\n",
    "                if _lambda is not None:\n",
    "                    prediction = self.b + self.b_u[i] + self.b_i[j] + self.U[i, :].dot(self.V[j, :].T)\n",
    "                    e = (r - prediction)\n",
    "                    # Update biases\n",
    "                    self.b_u[i] += self.alpha * (e - self._lambda * self.b_u[i])\n",
    "                    self.b_i[j] += self.alpha * (e - self._lambda * self.b_i[j])\n",
    "\n",
    "                    # Update user and item latent feature matrices\n",
    "                    self.U[i, :] += self.alpha * (e * self.V[j, :] - self._lambda * self.U[i,:])\n",
    "                    self.V[j, :] += self.alpha * (e * self.U[i, :] - self._lambda * self.V[j,:])\n",
    "                else:\n",
    "                    prediction = self.U[i, :].dot(self.V[j, :].T)\n",
    "                    e = (r - prediction)\n",
    "                    # Update user and item latent feature matrices\n",
    "                    self.U[i, :] += self.alpha * e * self.V[j, :]\n",
    "                    self.V[j, :] += self.alpha * e * self.U[i, :]\n",
    "                    \n",
    "        start_time = time.time()\n",
    "        # Initialize user and item latent feature matrice\n",
    "        self.U = np.random.normal(scale = 1./self.k, size = (self.nUser, self.k))\n",
    "        self.V = np.random.normal(scale = 1./self.k, size = (self.nItem, self.k))\n",
    "        \n",
    "        if _lambda is not None:\n",
    "            # Initialize the biases\n",
    "            self.b_u = np.zeros(self.nUser)\n",
    "            self.b_i = np.zeros(self.nItem)\n",
    "            self.b = np.mean(self.R_train[np.where(self.R_train != 0)])\n",
    "\n",
    "        # Create a list of training samples\n",
    "        self.samples = [\n",
    "            (i, j, self.R_train[i, j])\n",
    "            for i in range(self.nUser)\n",
    "            for j in range(self.nItem)\n",
    "            if self.R_train[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        # Perform stochastic gradient descent for number of iterations\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            sgd()\n",
    "#             mse_train, mse_test = self.mse()\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(\"Iteration: %d \" % (i + 1))\n",
    "#                 print(\"Iteration: %d ; train error = %.4f; test error = %.4f\" % (i + 1, mse_train, mse_test))\n",
    "                \n",
    "        if _lambda is not None:\n",
    "            self.result = self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.U.dot(self.V.T)\n",
    "        else:\n",
    "            self.result = self.U.dot(self.V.T)\n",
    "        \n",
    "        mse_train, mse_test = self.mse()\n",
    "        print('training is complete! it took %.2f s' % (time.time() - start_time))\n",
    "        print(\"train error = %.4f; test error = %.4f\" % (mse_train, mse_test))\n",
    "        return self.result\n",
    "    \n",
    "    def mse(self):\n",
    "        '''Compute the total mean square error for training and testing data'''\n",
    "        xTrain, yTrain = self.R_train.nonzero()\n",
    "        xTest, yTest = self.R_test.nonzero()\n",
    "        trainError, testError = 0, 0\n",
    "        for x, y in zip(xTrain, yTrain):\n",
    "            trainError += pow(self.R_train[x, y] - self.result[x, y], 2)\n",
    "            \n",
    "        for x, y in zip(xTest, yTest):\n",
    "            testError += pow(self.R_test[x, y] - self.result[x, y], 2)\n",
    "            \n",
    "        return np.sqrt(trainError), np.sqrt(testError)\n",
    "        \n",
    "    def correlation_similarity(self, k):\n",
    "        start_time = time.time()\n",
    "        self.result = self.R_train.copy()\n",
    "#         R_normal = (R.T - np.nanmean(R, axis = 1)).T # normalizing with the average\n",
    "        \n",
    "        R_sparse = sparse.csr_matrix(self.R_train)\n",
    "        S = cosine_similarity(R_sparse) # similarity \n",
    "        for row in np.arange(self.nUser): # for all users\n",
    "            idxS = np.argsort(S[row])\n",
    "#             for col in np.where(R[row] == 0)[0]: # for item(col) that doesn't have a rating\n",
    "            for col in np.arange(self.nItem): # for all items\n",
    "#                 print(row, col, R[row][col])\n",
    "                idx_n = np.where(self.R_train[:, col] > 0)[0]# the idx of users who rated this item\n",
    "#                 print(idx_n)\n",
    "                if np.size(idx_n) < k:\n",
    "                    self.result[row][col] = self.R_train[idx_n, col].mean()\n",
    "                else:\n",
    "                    idx_knn = idxS[np.isin(idxS, idx_n, assume_unique = True)][-k-1:-1] # idxS with ratings\n",
    "#                     idx_knn = idx_n[np.argsort(S[row][idx_n])][-k:]# idx of k-nearest neighbors\n",
    "#                 print(idx_knn)\n",
    "                    self.result[row][col] = self.R_train[idx_knn, col].mean() # mean of the knn rating for this item\n",
    "        print('training is complete! it took %.2f s' % (time.time() - start_time))\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_similarity(R):\n",
    "    start_time = time.time()\n",
    "    result = R.copy()\n",
    "    R_normal_nan = (R.T - np.nanmean(R, axis = 1)).T # normalizing with the average\n",
    "    R_normal_zero = np.nan_to_num(R_normal_nan, copy = True)\n",
    "    print(R)\n",
    "    R_sparse = sparse.csr_matrix(R_normal_zero)\n",
    "    S = cosine_similarity(R_sparse) # similarity \n",
    "    print(R_normal_zero)\n",
    "    for row in np.arange(R.shape[0]): # for all users\n",
    "        similarity = S[row]\n",
    "        idxS = np.argwhere(similarity > 0.)\n",
    "        R_S = R_normal_nan[idxS]\n",
    "        result[row] = np.nanmean(R_S, axis = 0)\n",
    "    print('training is complete! it took %.2f s' % (time.time() - start_time))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [2.5 2.  2.  ... 0.  0.  0. ]\n",
      " [3.  0.  0.  ... 0.  0.  0. ]\n",
      " [5.  0.  0.  ... 0.  0.  0. ]]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-414-323b781c083d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrelation_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-413-37eefa18b222>\u001b[0m in \u001b[0;36mcorrelation_similarity\u001b[0;34m(R)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mR_normal_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_normal_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mR_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_normal_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_sparse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_normal_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     77\u001b[0m                         self.format)\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Read matrix dimensions given, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correlation_similarity(R_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 \n",
      "Iteration: 20 \n",
      "training is complete! it took 50.56 s\n",
      "train error = 204.2289; test error = 121.3293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.7027215 , 4.33693953, 4.08562656, ..., 4.21682621, 4.21502434,\n",
       "        4.33077482],\n",
       "       [4.01905588, 3.63531399, 3.39480715, ..., 3.54744653, 3.54745645,\n",
       "        3.66168143],\n",
       "       [2.52581468, 2.19881993, 1.9320147 , ..., 2.09470072, 2.09120804,\n",
       "        2.20589518],\n",
       "       ...,\n",
       "       [3.05999193, 2.69855982, 2.76905344, ..., 3.1301858 , 3.12137232,\n",
       "        3.22730916],\n",
       "       [3.67085348, 3.3082022 , 3.06056092, ..., 3.21727928, 3.21677988,\n",
       "        3.33145243],\n",
       "       [4.29142238, 3.58806829, 3.45318063, ..., 3.49679645, 3.5012661 ,\n",
       "        3.63570256]])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf = recommendation_system(R_train, R_test)\n",
    "# mf.correlation_similarity(3)\n",
    "mf.matrix_factorization(k = 300, alpha = 0.01, _lambda = 0.01, iterations = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204.22888307712753, 121.32933523305672)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215.19221896310728"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.mse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bluesky/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:38: UserWarning: [Errno 12] Cannot allocate memory.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "tR = np.array([\n",
    "    [5, 3, np.nan, 1, 1],\n",
    "    [4, np.nan, np.nan, 1, 1],\n",
    "    [1, 1, np.nan, 5, 4],\n",
    "    [1, np.nan, np.nan, 4, 5],\n",
    "    [np.nan, 1, 5, 4, 4],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5       , 2.        , 2.75      , 3.33333333, 3.5       ])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(tR, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.5       ,  0.5       ,         nan, -1.5       , -1.5       ],\n",
       "       [ 2.        ,         nan,         nan, -1.        , -1.        ],\n",
       "       [-1.75      , -1.75      ,         nan,  2.25      ,  1.25      ],\n",
       "       [-2.33333333,         nan,         nan,  0.66666667,  1.66666667],\n",
       "       [        nan, -2.5       ,  1.5       ,  0.5       ,  0.5       ]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tR.T - np.nanmean(tR, axis = 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3., nan,  1.,  1.],\n",
       "       [ 1.,  1., nan,  5.,  4.],\n",
       "       [nan,  1.,  5.,  4.,  4.]])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = np.array([0, 2, 4])\n",
    "tR[h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'nUser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-366-3711bbfd3692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrelation_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-365-e1f35a41176b>\u001b[0m in \u001b[0;36mcorrelation_similarity\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mR_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_normal_zero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_sparse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnUser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# for all users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0midxS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#             for col in np.where(R[row] == 0)[0]: # for item(col) that doesn't have a rating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'nUser'"
     ]
    }
   ],
   "source": [
    "correlation_similarity(tR, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tR_sparse = sparse.csr_matrix(tR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 5])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = np.array([0, 1, 2])\n",
    "tR[4][h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.86091606, 0.42289003, 0.36896403, 0.18257419],\n",
       "       [0.86091606, 1.        , 0.42008403, 0.47058824, 0.14969624],\n",
       "       [0.42289003, 0.42008403, 1.        , 0.98019606, 0.62360956],\n",
       "       [0.36896403, 0.47058824, 0.98019606, 1.        , 0.59878495],\n",
       "       [0.18257419, 0.14969624, 0.62360956, 0.59878495, 1.        ]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4228900316110311"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - spatial.distance.cosine(tR[0], tR[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       ...,\n",
       "       [2.5, 2. , 2. , ..., 0. , 0. , 0. ],\n",
       "       [3. , 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [5. , 0. , 0. , ..., 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100)\n",
    "np.random.shuffle(x)\n",
    "training, test = x[:80], x[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([74, 58, 27, 14, 17, 70, 82,  0, 87, 65, 85, 79,  9, 33, 36, 72, 29,\n",
       "       96, 38, 52, 67, 53, 43, 21, 41, 11, 75, 62, 37, 30, 39, 25, 60, 97,\n",
       "       69, 80, 47, 71,  1, 26,  3, 59, 94, 45, 90, 12, 89, 28, 81, 76, 31,\n",
       "       83, 68, 98, 73, 55, 88, 66,  7, 78, 34, 16,  5, 95, 24, 42, 13, 19,\n",
       "       50, 10, 99, 46,  8, 61, 18, 20, 22, 32, 44, 92])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_R(nU, nI, f = 0.2, ft = 0.8):\n",
    "    R = np.zeros(shape = (nU, nI))\n",
    "    n = int(np.rint(f * nU * nI))\n",
    "    idxU = np.random.choice(np.arange(nU), size = n)\n",
    "    idxI = np.random.choice(np.arange(nI), size = n)\n",
    "    for x, y in zip(idxU, idxI):\n",
    "        R[x][y] = np.random.randint(low = 1, high = 10)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 2., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 4., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 4.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mR = mock_R(40, 50)\n",
    "mR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmR = recommendation_system(mR, mR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; train error = 49.3843; test error = 49.3843\n",
      "Iteration: 20 ; train error = 49.3843; test error = 49.3843\n",
      "training is complete! it took 0.12 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.9062603 , 4.90628366, 4.90625455, ..., 4.90661179, 4.90666117,\n",
       "        4.90663051],\n",
       "       [4.90656739, 4.90666464, 4.9065231 , ..., 4.9065938 , 4.90626056,\n",
       "        4.90630948],\n",
       "       [4.9065554 , 4.90644708, 4.90647314, ..., 4.90695252, 4.90680165,\n",
       "        4.90671574],\n",
       "       ...,\n",
       "       [4.90657811, 4.90677054, 4.90696317, ..., 4.90693909, 4.90658596,\n",
       "        4.90675202],\n",
       "       [4.90629563, 4.90659874, 4.90636596, ..., 4.9065348 , 4.90658854,\n",
       "        4.90662293],\n",
       "       [4.90647931, 4.90657469, 4.90645965, ..., 4.90672111, 4.90664056,\n",
       "        4.90670018]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmR.matrix_factorization(k = 300, alpha = 0.01, _lambda = 0.01, iterations = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
